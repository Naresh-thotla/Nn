{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-33-2026e77647e7>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-2026e77647e7>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    filename = os.path.join(OUTPUT_DIR, href.rsplit('/', 1)[-1])\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# Python 3.x\n",
    "from urllib.request import Request,urlopen, urlretrieve\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "URL = Request('http://www.censusindia.gov.in/2011census/HLO/HL_PCA/Houselisting-housing-AP.html', headers=headers)\n",
    "\n",
    "#URL = 'https://www.rbi.org.in/scripts/bs_viewcontent.aspx?Id=2009'\n",
    "\n",
    "OUTPUT_DIR = 'E:\\Census 2011'  # path to output folder, '.' or '' uses current folder\n",
    "\n",
    "u = urlopen(URL)\n",
    "try:\n",
    "   html = u.read().decode('utf-8')\n",
    "finally:\n",
    "   u.close()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "for link in soup.select('a[href^=\"\"]'):\n",
    "        href = link.get('href')\n",
    "        if not any(href.endswith(x) for x in ['.csv','.xls','.xlsx']):\n",
    "            continue\n",
    "\n",
    "    filename = os.path.join(OUTPUT_DIR, href.rsplit('/', 1)[-1])\n",
    "\n",
    "   # We need a https:// URL for this site\n",
    "# href = href.replace('http://','https://')\n",
    "\n",
    "  \n",
    "    print(\"Downloading %s to %s...\" % (href, filename) )\n",
    "urlretrieve(u+href, filename)\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "# Python 3.x\n",
    "from urllib.request import urlopen, urlretrieve, quote\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Remove the trailing / you had, as that gives a 404 page\n",
    "url = 'http://www.censusindia.gov.in/2011census/population_enumeration.html'\n",
    "OUTPUT_DIR = 'E:\\25052017'\n",
    "u = urlopen(url)\n",
    "try:\n",
    "    html = u.read().decode('utf-8')\n",
    "finally:\n",
    "    u.close()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "# Select all A elements with href attributes containing URLs starting with http://\n",
    "for link in soup.select('a[href^=\"\"]'):\n",
    "    sad = link.get('href')\n",
    "    #print (sad)\n",
    "    bad1 = urlopen(sad)\n",
    "    bad = BeautifulSoup(bad1, \"html.parser\")\n",
    "\n",
    "    for link in bad.select('a[href^=\"\"]'):\n",
    "        mad1=link.get('href')\n",
    "        #print (mad1)\n",
    "\n",
    "   # Make sure it has one of the correct extensions\n",
    "        if not any(mad1.endswith(x) for x in ['.csv','.xls','.xlsx']):\n",
    "            continue\n",
    "\n",
    "        filename = os.path.join(OUTPUT_DIR, mad1.rsplit('/', 1)[-1])\n",
    "        print(\"Downloading %s to %s...\" % ('http://www.censusindia.gov.in/2011census/HLO/HL_PCA/'+ mad1, filename) )\n",
    "        urlretrieve('http://www.censusindia.gov.in/2011census/' + mad1, filename)\n",
    "        print(\"Done.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HH_PCA1/HLPCA-35638-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-35638-2011_H14_census.xlsx to E:\\census\\HLPCA-35638-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-35639-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-35639-2011_H14_census.xlsx to E:\\census\\HLPCA-35639-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-35640-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-35640-2011_H14_census.xlsx to E:\\census\\HLPCA-35640-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06070-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06070-2011_H14_census.xlsx to E:\\census\\HLPCA-06070-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06081-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06081-2011_H14_census.xlsx to E:\\census\\HLPCA-06081-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06088-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06088-2011_H14_census.xlsx to E:\\census\\HLPCA-06088-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06078-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06078-2011_H14_census.xlsx to E:\\census\\HLPCA-06078-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06086-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06086-2011_H14_census.xlsx to E:\\census\\HLPCA-06086-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06080-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06080-2011_H14_census.xlsx to E:\\census\\HLPCA-06080-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06083-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06083-2011_H14_census.xlsx to E:\\census\\HLPCA-06083-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06077-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06077-2011_H14_census.xlsx to E:\\census\\HLPCA-06077-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06073-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06073-2011_H14_census.xlsx to E:\\census\\HLPCA-06073-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06074-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06074-2011_H14_census.xlsx to E:\\census\\HLPCA-06074-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06072-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06072-2011_H14_census.xlsx to E:\\census\\HLPCA-06072-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06084-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06084-2011_H14_census.xlsx to E:\\census\\HLPCA-06084-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06087-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06087-2011_H14_census.xlsx to E:\\census\\HLPCA-06087-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06089-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06089-2011_H14_census.xlsx to E:\\census\\HLPCA-06089-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06069-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06069-2011_H14_census.xlsx to E:\\census\\HLPCA-06069-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06075-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06075-2011_H14_census.xlsx to E:\\census\\HLPCA-06075-2011_H14_census.xlsx...\n",
      "Done.\n",
      "HH_PCA1/HLPCA-06085-2011_H14_census.xlsx\n",
      "Downloading http://www.censusindia.gov.in/2011census/HLO/HL_PCA/HH_PCA1/HLPCA-06085-2011_H14_census.xlsx to E:\\census\\HLPCA-06085-2011_H14_census.xlsx...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-71982402a0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmad1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Downloading %s to %s...\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'http://www.censusindia.gov.in/2011census/HLO/HL_PCA/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mmad1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://www.censusindia.gov.in/2011census/HLO/HL_PCA/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmad1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smc46\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smc46\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smc46\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smc46\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "# Python 3.x\n",
    "from urllib.request import urlopen, urlretrieve, quote\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Remove the trailing / you had, as that gives a 404 page\n",
    "url = 'http://www.censusindia.gov.in/2011census/HLO/HL_PCA/Houselisting-housing-HLPCA.html'\n",
    "OUTPUT_DIR = 'E:\\census'\n",
    "html = urlopen(url)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "# Select all A elements with href attributes containing URLs starting with http://\n",
    "for link in soup.select('a[href^=\"\"]'):\n",
    "    sad = link.get('href')\n",
    "    #print (sad)\n",
    "    bad1 = urlopen('http://www.censusindia.gov.in/2011census/HLO/HL_PCA/' + sad)\n",
    "    bad = BeautifulSoup(bad1, \"html.parser\")\n",
    "    i=1\n",
    "    for link in bad.select('a[href^=\"\"]'):\n",
    "        mad1=link.get('href')\n",
    "        print (mad1)\n",
    "\n",
    "   # Make sure it has one of the correct extensions\n",
    "        if not any(mad1.endswith(x) for x in ['.csv','.xls','.xlsx']):\n",
    "            continue\n",
    "\n",
    "        filename = os.path.join(OUTPUT_DIR, mad1.rsplit('/', 1)[-1])\n",
    "        print(\"Downloading %s to %s...\" % ('http://www.censusindia.gov.in/2011census/HLO/HL_PCA/'+ mad1, filename) )\n",
    "        urlretrieve('http://www.censusindia.gov.in/2011census/HLO/HL_PCA/' + mad1, filename)\n",
    "       \n",
    "        print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "old_file = 'E:\\Census 2011'+os.path.sep+'HLPCA-01001-2011_H14_census.xlsx'\n",
    "new_file = 'E:\\Census 2011'+os.path.sep+'ap.xlsx'\n",
    "os.rename(old_file,new_file)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
